version: '3.7'
services:
  proxy:
    restart: always
    image: nginx:latest
    container_name: code_proxy
    volumes:
      - '${PWD}/attackers/evil_proxy/nginx.conf:/etc/nginx/nginx.conf'
      - '${PWD}/log:/var/log'
    ports:
      - 11435:11435
    healthcheck:
      test: curl --fail http://localhost:11435/api/tags || exit 1
      interval: 60s
      retries: 5
      start_period: 20s
      timeout: 10s
    networks:
      llm:
        ipv4_address: 192.168.2.16
    depends_on:
      evil_puller:
        condition: service_completed_successfully

  code_interceptor:
    container_name: code_interceptor
    hostname: code_interceptor
    restart: always
    build:
      context: attackers/code_interceptor
      dockerfile: Dockerfile
    image: 'moditm-code_interceptor:latest'
    environment:
      OLLAMA_URL: badllama
      OLLAMA_PORT: 11434
    volumes:
      - '${PWD}/log:/var/log'
      - '${PWD}/config:/config'
    expose:
      - 11434
    networks:
      llm:
        ipv4_address: 192.168.2.32
    stdin_open: true # docker run -i
    tty: true        # docker run -t

  badllama:
    container_name: badllama
    hostname: badllama
    restart: always
    build:
      context: codellama
      dockerfile: Dockerfile
    image: 'moditm-llm-codellama:latest'
    expose:
      - 11434
    volumes:
      - '${PWD}/badllama:/root/.ollama'
    command: serve 
    healthcheck:
      test: curl --fail http://localhost:11434/api/tags || exit 1
      interval: 30s
      retries: 2
      start_period: 20s
      timeout: 2s
    networks:
      llm:
        ipv4_address: 192.168.2.64
    
  evil_puller:
    image: 'curlimages/curl:8.6.0'
    environment:
      OLLAMA_HOST: '192.168.2.64'
      OLLAMA_PORT: 11434
    volumes:
      - '${PWD}/attackers/model_puller:/model_puller'
    command: "/model_puller/pull.sh"
    networks:
      - llm
    depends_on:
      badllama:
        condition: service_healthy
networks:
  llm:
    name: llm
    external: true